# Visual Affective Computing Survey

--------------------------------------------------------------
## üìñ Reviews

* [2022 TPAMI] **Affective Image Content Analysis: Two Decades Review and New Perspectives**, Sicheng Zhao; Xingxu Yao; Jufeng Yang; Guoli Jia; Guiguang Ding; Tat-Seng Chua; Bj√∂rn W. Schuller; Kurt Keutzer
  [[Paper](https://ieeexplore.ieee.org/document/9472932)]


--------------------------------------------------------------
## üì∑ Image Tasks
### üåè Open-world Image Emotion Classification
```
  Classification, Image Similarity Metric, Emotion Distribution, 
```

* [2023 ACM MM] **Progressive Visual Content Understanding Network for Image Emotion Classification**, Jicai Pan, Shangfei Wang
  [[Paper](https://dl.acm.org/doi/abs/10.1145/3581783.3612186)]


* [2023 ACM MM] **StyleEDL: Style-Guided High-order Attention Network for Image Emotion Distribution Learning**, Peiguang Jing, Xianyi Liu, Ji Wang, Yinwei Wei, Liqiang Nie, Yuting Su
  [[Paper](https://dl.acm.org/doi/abs/10.1145/3581783.3612040)]

* [2023 TMM] **Multiscale Emotion Representation Learning for Affective Image Recognition**, Haimin Zhang; Min Xu
  [[Paper](https://ieeexplore.ieee.org/document/9693105)]


* [2022 IJCAI] **Automatic Recognition of Emotional Subgroups in Images**, Emmeke Veltmeijer , Charlotte Gerritsen and Koen Hindriks
  [[Paper](https://doi.org/10.24963/ijcai.2022/190)] [[Code](https://github.com/Emmekea/emotional-subgroup-recognition)] 

* [2021 TMM] **Weakly Supervised Emotion Intensity Prediction for Recognition of Emotions in Images**, Haimin Zhang; Min Xu
  [[Paper](https://ieeexplore.ieee.org/document/9136892)]

* [2021 TMM] **Image-Text Multimodal Emotion Classification via Multi-View Attentional Network**, Xiaocui Yang; Shi Feng; Daling Wang; Yifei Zhang
  [[Paper](https://ieeexplore.ieee.org/document/9246699)]
  
* [2019 AAAI] **CycleEmotionGAN: Emotional Semantic Consistency Preserved CycleGAN for Adapting Image Emotions**, Sicheng Zhao, Chuang Lin, Pengfei Xu, Sendong Zhao, Yuchen Guo, Ravi Krishna, Guiguang Ding, Kurt Keutzer
  [[Paper](https://doi.org/10.1609/aaai.v33i01.33012620)]


* [2019 AAAI] **Structured and Sparse Annotations for Image Emotion Distribution Learning**, Haitao Xiong, Hongfu Liu, Bineng Zhong, Yun Fu
  [[Paper](https://doi.org/10.1609/aaai.v33i01.3301363)]



### üåè Open-world Emotion Image Captioning

* [2022 CVPR] **It is Okay to Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning by Contrastive Data Collection**, Mohamed, Youssef; Khan, Faizan Farooq; Haydarov, Kilichbek; Elhoseiny, Mohamed
  [[Paper](https://ieeexplore.ieee.org/document/9878621)] [[Code](https://www.artemisdataset-v2.org/)]

* [2021 ACM MM] **Similar Scenes Arouse Similar Emotions: Parallel Data Augmentation for Stylized Image Captioning**, Guodun Li, Yuchen Zhai, Zehao Lin, Yin Zhang
  [[Paper](https://dl.acm.org/doi/10.1145/3474085.3475662)] 


* [2020 ACM MM] **AffectI: A Game for Diverse, Reliable, and Efficient Affective Image Annotation**, Xingkun Zuo, Jiyi Li, Qili Zhou, Jianjun Li, Xiaoyang Mao
  [[Paper](https://dl.acm.org/doi/10.1145/3394171.3413744)] 


* [2019 ACM MM] **Towards Increased Accessibility of Meme Images with the Help of Rich Face Emotion Captions**, K R Prajwal, C V Jawahar, Ponnurangam Kumaraguru
  [[Paper](https://dl.acm.org/doi/10.1145/3343031.3350939)] [[Code](http://precog.iiitd.edu.in/research/social-media-4-all)]

  
### üåè Open-world Emotion Image Retrieval

* [2021 TMM] **APSE: Attention-Aware Polarity-Sensitive Embedding for Emotion-Based Image Retrieval**, Xingxu Yao; Sicheng Zhao; Yu-Kun Lai; Dongyu She; Jie Liang; Jufeng Yang
  [[Paper](https://ieeexplore.ieee.org/document/9281019)]

* [2021 TMM] **Adaptive Deep Metric Learning for Affective Image Retrieval and Classification**, Xingxu Yao; Dongyu She; Haiwei Zhang; Jufeng Yang; Ming-Ming Cheng; Liang Wang
  [[Paper](https://ieeexplore.ieee.org/document/9113756)]

* [2020 ACM MM] **Attention-Aware Polarity Sensitive Embedding for Affective Image Retrieval**, Sicheng Zhao, Yaxian Li, Xingxu Yao, Weizhi Nie, Pengfei Xu, Jufeng Yang, Kurt Keutzer
  [[Paper](https://dl.acm.org/doi/10.1145/3394171.3413776)]

  
* [2019 ICCV] **Emotion-Based End-to-End Matching Between Image and Music in Valence-Arousal Space**, Xingxu Yao; Dongyu She; Sicheng Zhao; Jie Liang; Yu-Kun Lai; Jufeng Yang
  [[Paper](https://ieeexplore.ieee.org/document/9008797)]


### üåè Open-world Emotion Image Editing

* [2021 TMM] **Emotion Attention-Aware Collaborative Deep Reinforcement Learning for Image Cropping**, Xiaoyan Zhang; Zhuopeng Li; Jianmin Jiang
  [[Paper](https://ieeexplore.ieee.org/document/9158370)]


### üòä Macro Facial Expression Recognition

* [2020 IJCNN] **Emotion Recognition from Face Images in an Unconstrained Environment for usage on Social Robots**, Nicola Webb; Ariel Ruiz-Garcia; Mark Elshaw; Vasile Palade
  [[Paper](https://ieeexplore.ieee.org/document/9207494)]

  
### üòä Micro Facial Expression Recognition 


### üòä Emotion-Image-based Talking Face Generation

* [2022 TMM] **Speech Driven Talking Face Generation From a Single Image and an Emotion Condition**, Sefik Emre Eskimez; You Zhang; Zhiyao Duan
  [[Paper](https://ieeexplore.ieee.org/document/9496264)]




------------------------------------------------------------------
## üé¨ Video Tasks


### üìù Emotional Video Captioning

* [2023 ACM MM] **Emotion-Prior Awareness Network for <u>Emotional Video Captioning</u>**, Peipei Song, Dan Guo, Xun Yang, Shengeng Tang, Erkun Yang, Meng Wang
  [[Paper](https://dl.acm.org/doi/abs/10.1145/3581783.3611726)]  [[Code](https://github.com/songpipi/EPAN)]




### ‚ö™Ô∏è Video Emotion Recognition (In-the-Lab.)

* [2023 ACM MM] **ViPER: Video-based Perceiver for Emotion Recognition**, Lorenzo Vaiani, Moreno La Quatra, Luca Cagliero, Paolo Garza
  [[Paper](https://dl.acm.org/doi/10.1145/3551876.3554806)]


### üòä Emotion-Video-based Talking Face Generation

* [2023 AAAI] **StyleTalk: One-Shot Talking Head Generation with Controllable Speaking Styles**, Yifeng Ma1, Suzhen Wang, Zhipeng Hu, Changjie Fan, Tangjie Lv, Yu Ding, Zhidong Deng, Xin Yu
  [[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/25280)]  [[Code](https://github.com/FuxiVirtualHuman/styletalk)]



* [2023 CVPR] [Microsoft/HKUST] **MetaPortrait: ldentity-Preserving Talking Head Generation with Fast Personalized Adaptation**, Bowen Zhang, Chenyang Qi, Pan Zhang1 Bo Zhang, HsiangTao Wu, Dong Chen, Qifeng Chen, Yong Wang, Fang Wen 
  [[Paper](https://ieeexplore.ieee.org/document/10205008)]  [[Code](https://meta-portrait.github.io/)]


* [2023 CVPR] [Xiaobing.AI] **Progressive Disentangled Representation Learning for Fine-Grained Controllable Talking Head Synthesis**, Duomin Wang, Yu Deng, Zixin Yin, Heung-Yeung Shum, Baoyuan Wang 
  [[Paper](https://arxiv.org/pdf/2211.14506.pdf)]  [[Code](https://dorniwang.github.io/PD-FGC/)]

  
* [2023 CVPR] [Shanghai AI Laboratory/Northwestern Polytechnical University] **One-Shot High-Fidelity Talking-Head Synthesis with Deformable Neural Radiance Field**, Weichuang Li; Longhao Zhang; Dong Wang; Bin Zhao; Zhigang Wang; Mulin Chen; Bang Zhang; Zhongjian Wang; Liefeng Bo; Xuelong Li 
  [[Paper](https://ieeexplore.ieee.org/document/10203662)]  [[Code](https://www.waytron.net/hidenerf/)]

  
* [2023 CVPR] [Microsoft Research] **High-Fidelity and Freely Controllable Talking Head video Generation**, Yue Gao, Yuan Zhou, Jinglu Wang, Xiao Li, Xiang Ming, Yan Lu 
  [[Paper](https://ieeexplore.ieee.org/document/10204552)] 

  
* [2022 CVPR] **Expressive Talking Head Generation with Granular Audio-Visual Control**,  
  [[Paper]( )]  [[Code]( )]

  
* [2022 CVPR] **Depth-Aware Generative Adversarial Network for Talking Head Video Generation**,  
  [[Paper]( )]  [[Code]( )]


* [2021 AAAI] **Write-a-speaker: Text-based Emotional and Rhythmic Talking-head Generation**, Lincheng Li, Suzhen Wang, Zhimeng Zhang, Yu Ding, Yixing Zheng, Xin Yu, Changjie Fan
  [[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/16286)]  [[Code](https://github.com/FuxiVirtualHuman/Write-a-Speaker)]


* [2021 CVPR] **One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing**,  
  [[Paper]( )]  [[Code]( )]


  
* [2020 CVPR] **DAVD-Net: Deep Audio-Aided Video Decompression of Talking Heads**,  
  [[Paper]( )]  [[Code]( )]















